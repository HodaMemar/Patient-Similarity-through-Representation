{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph_Sequence.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdjAR+0ScvsvcxV694a4sl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HodaMemar/Patient-Similarity-through-Representation/blob/main/Graph_Sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q5WAq5fNdgke"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVuwZmXLdbHl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage refers to the set of quadraples that are used to make the graph.\n",
        "This collection is arranged according to the time dimension"
      ],
      "metadata": {
        "id": "KRGJRGMJepXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Stage_df1=pd.read_csv('...\\\\Stage.csv')"
      ],
      "metadata": {
        "id": "iFN-Bpw6dfxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We designed two types of stages to design two methods U-TTree and H_U_TTree. which is in H_U_TTree data extracted from past medical history."
      ],
      "metadata": {
        "id": "_2a9-lIrfSnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_Subject_id=Stage_df1['Subject_id'].unique().tolist()\n",
        "list_Events=['procedure','Drug','past medical history']\n",
        "foot_print=[]\n",
        "Subgraph_id_num=3\n",
        "list_sen=[]\n",
        "counter=1\n",
        "print(len(list_Subject_id))\n",
        "for row_1 in list_Subject_id:\n",
        "    root=''\n",
        "    G = nx.Graph()\n",
        "    foot_print=[]\n",
        "    foot_print.append('DiseaseDisorderMention')\n",
        "    foot_print.append('procedure')\n",
        "    foot_print.append('Drug')\n",
        "    label=\"Patient_\"\n",
        "    foot_print.append(label+str(row_1))\n",
        "    G.add_node(label+str(row_1))\n",
        "    root=label+str(row_1)\n",
        "    for row_2 in range(Subgraph_id_num):\n",
        "            label=\"SG_\"\n",
        "            \n",
        "            G.add_node(label+str(row_2))\n",
        "            foot_print.append(label+str(row_2))\n",
        "            G.add_edge(\"Patient_\"+str(row_1), label+str(row_2))\n",
        "            if row_2==1:\n",
        "                list_Timestame=Stage_df1.loc[Stage_df1['Subject_id']==row_1]['Timestame_id'].unique().tolist()\n",
        "                list_Timestame.sort()\n",
        "                for index, row_3 in enumerate(list_Timestame):\n",
        "                    label=\"T_\"\n",
        "                    \n",
        "                    current=label+str(index)\n",
        "\n",
        "                    G.add_node(current)\n",
        "                    foot_print.append(current)\n",
        "                    \n",
        "                    if index==0:\n",
        "                            previous=\"SG_\"+str(row_2)\n",
        "                            \n",
        "                            \n",
        "                    elif index>0:\n",
        "                            previous = label+str(index-1)\n",
        "                            \n",
        "                    G.add_edge(previous, current)\n",
        "                    foot_print.append(previous)\n",
        "                    \n",
        "                    list_Events=[]        \n",
        "                    list_Events=list(Stage_df1.loc[(Stage_df1['Subject_id']==row_1) & (Stage_df1['Subgraph_id']==row_2) & (Stage_df1['Timestame_id']==row_3)]['Event type'].unique())\n",
        "                        \n",
        "                    #print(list_Events)\n",
        "                    for row_4 in list_Events:\n",
        "                            label=\"T\"+str(index) + \"_E \"\n",
        "                            \n",
        "                            foot_print.append(\"T\"+str(index) + \"_E\")\n",
        "                           \n",
        "                            inx=list(Stage_df1.index[(Stage_df1['Subject_id']==row_1) & (Stage_df1['Subgraph_id']==row_2) & (Stage_df1['Timestame_id']==row_3)& (Stage_df1['Event type']==row_4)])\n",
        "                            \n",
        "                            entity=label +str(row_4)+' '+str(Stage_df1.iloc[inx[0]]['entity'])\n",
        "                            value=''\n",
        "                            for index, row_5 in enumerate(inx):\n",
        "                                value=value+' '+Stage_df1.iloc[row_5]['value']\n",
        "                            value=label +str(row_4)+' '+value\n",
        "\n",
        "                            G.add_node(entity+' '+value)\n",
        "                            G.add_edge(current, entity+' '+value)\n",
        "    \n",
        "    #graph_plit(G)\n",
        "    list_sen.append([row_1,traverse_tree(G,root,foot_print)])\n",
        "    print(counter,row_1)\n",
        "    counter=counter+1    "
      ],
      "metadata": {
        "id": "7x0Hww2zdfuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen=pd.DataFrame(list_sen,columns=['Subject_id','String']) "
      ],
      "metadata": {
        "id": "hf3RtDAtdfsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def traverse_tree(G,source,foot_print):\n",
        "    T = nx.bfs_tree(G, source=root)\n",
        "    bfs_string=list(T.nodes())\n",
        "    \n",
        "    new=[]\n",
        "    stopwords = foot_print\n",
        "    tokenized_sents = [word_tokenize(i) for i in bfs_string]\n",
        "    for i in tokenized_sents:\n",
        "        words=i\n",
        "        for word in list(words):  # iterating on a copy since removing will mess things up\n",
        "            if word in stopwords:\n",
        "                words.remove(word)\n",
        "        if(len(words)>0):\n",
        "            new.append(words)  \n",
        "    sen=''\n",
        "    for i in range(len(new)):\n",
        "        sen=sen +' '+(' '.join(map(str, new[i])))\n",
        "    return(sen) "
      ],
      "metadata": {
        "id": "KMGYGnlIdfpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell we can plot a generated graph."
      ],
      "metadata": {
        "id": "8YShpfIVgDld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_plit(G):\n",
        "    \n",
        "    G.nodes\n",
        "    plt.figure(1)\n",
        "    plt.figure(2,figsize=(12,12))\n",
        "    \n",
        "    list_root=[label+str(row_1)]\n",
        "    list_subgraph=['SG_1','SG_2','SG_0']\n",
        "    list_Time=['T_1','T_2']\n",
        "    pos=nx.spring_layout(G)\n",
        "\n",
        "    nx.draw(G, pos=pos, node_size = 1200, with_labels=True,node_color = 'silver')\n",
        "    nx.draw_networkx_nodes(G, pos=pos,nodelist = list_root, node_color = 'red', node_size = 1500)\n",
        "    nx.draw_networkx_nodes(G, pos=pos,nodelist = list_subgraph, node_color = 'orange', node_size = 1400)\n",
        "    nx.draw_networkx_nodes(G, pos=pos,nodelist = list_Time, node_color = 'gold', node_size = 1300)\n",
        "    nx.draw(G,with_labels=True,node_size = 1500,node_color = 'cyan')\n",
        "    nx.draw_networkx_nodes(G, nodelist = ['Patient_1'], node_color = 'red', node_size = 200)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZceHqS3HdfnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When method breadth first search is used to traverse the generated tree, the following alternative way can be used to generate compounds.\n",
        "What is important is to maintain the order of clinical events in each time window. "
      ],
      "metadata": {
        "id": "Nw68bQbSgJiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls_doc_patient=[]\n",
        "for i in range(len(ls_patient)):\n",
        "    try:\n",
        "    #for each patients\n",
        "        print(ls_patient[i])\n",
        "        df_tmp=Stage_Total.loc[Stage_Total['admission_Id']==ls_patient[i]]\n",
        "        ls_time=df_tmp.Timestame_id.unique().tolist()\n",
        "        ls_time.sort()\n",
        "        UnD=Stage_df_Note.loc[(Stage_df_Note['ID']==ls_patient[i]),['ICD'] ].values[0]\n",
        "       \n",
        "\n",
        "        doc_S_Non_TT=''\n",
        "        doc_U_Non_TT=''\n",
        "        doc_S_TT=''\n",
        "        doc_S_U_TT=''\n",
        "        doc_S_U_TT_R='' \n",
        "        for j in range(len(ls_time)):\n",
        "            # in each time windows\n",
        "            df_tmp_ent=df_tmp.loc[df_tmp['Timestame_id']==ls_time[j]]\n",
        "            df_tmp_ent=df_tmp_ent.sort_values('entity')\n",
        "\n",
        "            tmp_S_Non_TT=''\n",
        "            tmp_U_Non_TT=''\n",
        "            tmp_S_TT=''\n",
        "            tmp_S_U_TT=''\n",
        "            tmp_S_U_TT_R=''\n",
        "            \n",
        "            for k in range(len(df_tmp_ent)):\n",
        "                tmp_S_Non_TT=tmp_S_Non_TT+ ' ' + re.sub(r\"\\W+|_-\", \"\", df_tmp_ent.iloc[k].entity) \n",
        "            doc_S_Non_TT=doc_S_Non_TT+ tmp_S_Non_TT   \n",
        "    #---------------------------------------------------------        \n",
        "            for k in range(len(df_tmp_ent)):\n",
        "                tmp_S_TT=tmp_S_TT + re.sub(r\"\\W+|_-\", \"\", df_tmp_ent.iloc[k].entity) + \\\n",
        "                                               re.sub(r\"\\W+|_-\", \"\", df_tmp_ent.iloc[k].value)\n",
        "            doc_S_TT=doc_S_TT+ ' ' +tmp_S_TT    \n",
        "    #---------------------------------------------------------                                                \n",
        "\n",
        "            tmp_S_U_TT_R=tmp_S_U_TT_R+' '+tmp_S_TT+' '+ re.sub(r\"\\W+|_-\", \" \", str(UnD))\n",
        "            doc_S_U_TT_R=doc_S_U_TT_R+ ' ' +tmp_S_U_TT_R\n",
        "\n",
        "        doc_S_U_TT=doc_S_TT + ' ' + UnD\n",
        "        doc_U_Non_TT=df_U_pref.loc[df_U['ID']==ls_patient[i]].Doc\n",
        "        ls_doc_patient.append([ls_patient[i],doc_S_Non_TT,doc_U_Non_TT,doc_S_TT,doc_S_U_TT,doc_S_U_TT_R])\n",
        "            \n",
        "    except:       \n",
        "        print('error')\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "st=pd.DataFrame(ls_doc_patient,columns=['ID','doc_S_Non_TT','doc_U_Non_TT','doc_S_TT','doc_S_U_TT','doc_S_U_TT_R']) \n",
        "st"
      ],
      "metadata": {
        "id": "ELVc2J9Gdfkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PtGAuUH4dfik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pUZq9C5vdff9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}